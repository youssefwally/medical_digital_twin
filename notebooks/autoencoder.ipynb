{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from itertools import tee\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GAE, LayerNorm, Linear\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registeration_path = \"../../local_data/registered_only/male/1000180/\"\n",
    "registeration_path = \"../../local_data/registered_only/male/1000180\"\n",
    "pt_data = \"../../local_data/organ_meshes/1000071/liver_mesh.pt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'sparse_csr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m registered_mesh\u001b[39m.\u001b[39mappend((vertices\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32), edges_torch))\n\u001b[0;32m     16\u001b[0m data \u001b[39m=\u001b[39m Data(x\u001b[39m=\u001b[39mregistered_mesh[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m], edge_index\u001b[39m=\u001b[39mregistered_mesh[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m], num_nodes\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(registered_mesh[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]))\n\u001b[1;32m---> 17\u001b[0m data \u001b[39m=\u001b[39m train_test_split_edges(data)\n\u001b[0;32m     18\u001b[0m data\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\deprecation.py:23\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mdetails\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m warnings\u001b[39m.\u001b[39mwarn(out)\n\u001b[1;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\utils\\train_test_split_edges.py:81\u001b[0m, in \u001b[0;36mtrain_test_split_edges\u001b[1;34m(data, val_ratio, test_ratio)\u001b[0m\n\u001b[0;32m     79\u001b[0m     data\u001b[39m.\u001b[39mtrain_pos_edge_index, data\u001b[39m.\u001b[39mtrain_pos_edge_attr \u001b[39m=\u001b[39m out\n\u001b[0;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     data\u001b[39m.\u001b[39mtrain_pos_edge_index \u001b[39m=\u001b[39m to_undirected(data\u001b[39m.\u001b[39;49mtrain_pos_edge_index)\n\u001b[0;32m     83\u001b[0m \u001b[39m# Negative edges.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m neg_adj_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(num_nodes, num_nodes, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39muint8)\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\utils\\undirected.py:173\u001b[0m, in \u001b[0;36mto_undirected\u001b[1;34m(edge_index, edge_attr, num_nodes, reduce)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_attr, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    171\u001b[0m     edge_attr \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mcat([e, e], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m edge_attr]\n\u001b[1;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m coalesce(edge_index, edge_attr, num_nodes, reduce)\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\utils\\coalesce.py:94\u001b[0m, in \u001b[0;36mcoalesce\u001b[1;34m(edge_index, edge_attr, num_nodes, reduce, is_sorted, sort_by_row)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"Row-wise sorts :obj:`edge_index` and removes its duplicated entries.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mDuplicate entries in :obj:`edge_attr` are merged by scattering them\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mtogether according to the given :obj:`reduce` option.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m    tensor([1., 1., 1.]))\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m nnz \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m num_nodes \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     96\u001b[0m idx \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mnew_empty(nnz \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     97\u001b[0m idx[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\utils\\num_nodes.py:27\u001b[0m, in \u001b[0;36mmaybe_num_nodes\u001b[1;34m(edge_index, num_nodes)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m num_nodes\n\u001b[0;32m     26\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, Tensor):\n\u001b[1;32m---> 27\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n\u001b[0;32m     28\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(edge_index\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(edge_index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m edge_index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:66\u001b[0m, in \u001b[0;36mis_torch_sparse_tensor\u001b[1;34m(src)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39msparse_coo:\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39;49msparse_csr:\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39msparse_csc:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'sparse_csr'"
     ]
    }
   ],
   "source": [
    "registered_mesh = []\n",
    "organ = \"liver_mesh.ply\"\n",
    "mesh = o3d.io.read_triangle_mesh(os.path.join(registeration_path, organ))\n",
    "\n",
    "vertices_data = np.asarray(mesh.vertices)\n",
    "triangles = np.asarray(mesh.triangles)\n",
    "vertices = torch.from_numpy(vertices_data).double()\n",
    "edges = []\n",
    "for triangle in triangles:\n",
    "    edges.append([triangle[0], triangle[1]])\n",
    "    edges.append([triangle[0], triangle[2]])\n",
    "    edges.append([triangle[1], triangle[2]])\n",
    "edges_torch = torch.from_numpy(np.unique(np.array(edges), axis=0).reshape(2,-1)).long()\n",
    "\n",
    "registered_mesh.append((vertices.type(torch.float32), edges_torch))\n",
    "data = Data(x=registered_mesh[0][0], edge_index=registered_mesh[0][1], num_nodes= len(registered_mesh[0][0]))\n",
    "data = train_test_split_edges(data)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnn_layers(num_conv_layers: int, hidden_channels, num_inp_features:int, \n",
    "                 gnn_layer, activation=nn.ReLU, normalization=None, dropout = None):\n",
    "    \"\"\"Creates GNN layers\"\"\"\n",
    "    layers = nn.ModuleList()\n",
    "\n",
    "    for i, j in enumerate(range(1,num_conv_layers,1)):\n",
    "        if i == 0:\n",
    "            layers.append(gnn_layer(num_inp_features, hidden_channels[i]))\n",
    "            layers.append(activation())\n",
    "            if normalization is not None:\n",
    "                layers.append(normalization(hidden_channels[i]))\n",
    "        else:\n",
    "            layers.append(gnn_layer(hidden_channels[i-1], hidden_channels[i]))\n",
    "            layers.append(activation())\n",
    "            if normalization is not None:\n",
    "                layers.append(normalization(hidden_channels[i]))\n",
    "\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "def get_mlp_layers(channels: list, activation, output_activation=nn.Identity):\n",
    "    \"\"\"Define basic multilayered perceptron network.\"\"\"\n",
    "    layers = []\n",
    "    *intermediate_layer_definitions, final_layer_definition = pairwise(channels)\n",
    "\n",
    "    for in_ch, out_ch in intermediate_layer_definitions:\n",
    "        intermediate_layer = nn.Linear(in_ch, out_ch)\n",
    "        layers += [intermediate_layer, activation()]\n",
    "\n",
    "    layers += [nn.Linear(*final_layer_definition), output_activation()]\n",
    "    #print('Output activation ',output_activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"\"\"Iterate over all pairs of consecutive items in a list.\n",
    "    Notes\n",
    "    -----\n",
    "        [s0, s1, s2, s3, ...] -> (s0,s1), (s1,s2), (s2, s3), ...\n",
    "    \"\"\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def train(model, optimizer, x, train_pos_edge_index):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(model, x, train_pos_edge_index, pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_channels, activation, normalization, num_conv_layers=4, layer='gcn',\n",
    "                 use_input_encoder=True, encoder_features=128, apply_batch_norm=True,\n",
    "                 apply_dropout_every=True, dropout = 0):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        self.fc = torch.nn.ModuleList()\n",
    "        self.layer_type = layer\n",
    "        self.use_input_encoder = use_input_encoder\n",
    "        self.apply_batch_norm = apply_batch_norm\n",
    "        self.dropout = dropout\n",
    "        self.normalization_bool = normalization\n",
    "        self.activation = activation\n",
    "        self.apply_dropout_every = apply_dropout_every\n",
    "\n",
    "        if self.normalization_bool:\n",
    "            self.normalization = LayerNorm\n",
    "        else:\n",
    "            self.normalization = None\n",
    "\n",
    "        if self.use_input_encoder :\n",
    "            self.input_encoder = get_mlp_layers(\n",
    "                channels=[in_features, encoder_features],\n",
    "                activation=nn.ELU,\n",
    "            )\n",
    "            in_features = encoder_features\n",
    "\n",
    "        if layer == 'gcn':\n",
    "            self.layers = get_gnn_layers(num_conv_layers, hidden_channels, num_inp_features=in_features,\n",
    "                                        gnn_layer=GCNConv,activation=activation,normalization=self.normalization )\n",
    "        elif layer == 'sageconv':\n",
    "            self.layers = get_gnn_layers(num_conv_layers, hidden_channels,in_features,\n",
    "                                        gnn_layer=SAGEConv,activation=activation,normalization=self.normalization )\n",
    "        elif layer == 'gat':\n",
    "            self.layers = get_gnn_layers(num_conv_layers, hidden_channels,in_features,\n",
    "                                        gnn_layer=GATConv,activation=activation,normalization=self.normalization )        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        if self.use_input_encoder:\n",
    "            x = self.input_encoder(x)\n",
    "\n",
    "        if self.normalization is None:\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                # Each GCN consists 2 modules GCN -> Activation \n",
    "                # GCN send edge index\n",
    "                if i% 2 == 0:\n",
    "                    x = layer(x, edge_index)\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "\n",
    "                if self.apply_dropout_every:\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        else:\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                # Each GCN consists 3 modules GCN -> Activation ->  Normalization \n",
    "                # GCN send edge index\n",
    "                if i% 3 == 0:\n",
    "                    x = layer(x, edge_index)\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "\n",
    "                if self.apply_dropout_every:\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = getattr(nn, \"ReLU\")\n",
    "model_params = dict(\n",
    "        use_input_encoder = False,\n",
    "        in_features= 3, \n",
    "        encoder_features = 128,\n",
    "        hidden_channels= [512, 256, 128, 64],\n",
    "        activation=activation,\n",
    "        normalization = True,\n",
    "        layer = \"gcn\",\n",
    "        num_conv_layers = 4,\n",
    "        dropout = 0.5)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_pos_edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\data\\storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\data\\storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train_pos_edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m train_pos_edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mtrain_pos_edge_index\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m \u001b[39m# inizialize the optimizer\u001b[39;00m\n\u001b[0;32m     11\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\data\\data.py:441\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[1;32mc:\\Users\\yussu\\anaconda3\\envs\\local_digital_twin_env\\lib\\site-packages\\torch_geometric\\data\\storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     82\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_pos_edge_index'"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = GAE(GNN(**model_params))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, optimizer, x, train_pos_edge_index)\n",
    "\n",
    "    test_pos_edge_index = data.test_pos_edge_index.to(device)\n",
    "    test_neg_edge_index = data.test_neg_edge_index.to(device)\n",
    "\n",
    "    auc, ap = test(model, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index)\n",
    "    if(epoch % 10 == 0):\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = model.encode(x, train_pos_edge_index)\n",
    "print(f'latent space: {Z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n",
      "(tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], grad_fn=<MulBackward0>), tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), None, tensor([0, 0, 0, 0]), tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.], grad_fn=<IndexBackward0>))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import TopKPooling, SAGPooling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "x = torch.zeros(4,5, dtype=int)\n",
    "print(x)\n",
    "pool_layer = TopKPooling(in_channels=5, ratio=64)\n",
    "x = pool_layer(x,x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_digital_twin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

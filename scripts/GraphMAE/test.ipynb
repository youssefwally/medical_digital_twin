{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-10-15 16:19:25,614 - instantiator - Created a temporary directory at /tmp/tmpi08_v8ai\n",
      "INFO - 2023-10-15 16:19:25,616 - instantiator - Writing /tmp/tmpi08_v8ai/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import dgl\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from graphmae.utils import (\n",
    "    build_args,\n",
    "    create_optimizer,\n",
    "    set_random_seed,\n",
    "    TBLogger,\n",
    "    get_current_lr,\n",
    "    load_best_configs,\n",
    ")\n",
    "from graphmae.datasets.data_util import load_graph_classification_dataset\n",
    "from graphmae.models import build_model\n",
    "from graphmae.evaluation import linear_probing_for_inductive_node_classiifcation, LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_mesh_to_adjacency_matrix(mesh):\n",
    "    # Get the vertices and triangles of the mesh\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    triangles = np.asarray(mesh.triangles)\n",
    "\n",
    "    # Create an empty adjacency matrix\n",
    "    n_vertices = len(vertices)\n",
    "    adjacency_matrix = sp.lil_matrix((n_vertices, n_vertices), dtype=np.float32)\n",
    "\n",
    "    # Iterate through the triangles and add edges to the adjacency matrix\n",
    "    for tri in triangles:\n",
    "        adjacency_matrix[tri[0], tri[1]] = 1.0\n",
    "        adjacency_matrix[tri[1], tri[0]] = 1.0\n",
    "        adjacency_matrix[tri[1], tri[2]] = 1.0\n",
    "        adjacency_matrix[tri[2], tri[1]] = 1.0\n",
    "        adjacency_matrix[tri[2], tri[0]] = 1.0\n",
    "        adjacency_matrix[tri[0], tri[2]] = 1.0\n",
    "\n",
    "    # Convert the adjacency matrix to a more efficient sparse matrix representation\n",
    "    adjacency_matrix = adjacency_matrix.tocsr()\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def open3d_to_dgl_graph(path, open3d_geometry):\n",
    "    intensity_path = path.replace(\"registered_meshes\",\"organ_decimations_ply\")\n",
    "    intensity_mesh = o3d.io.read_triangle_mesh(intensity_path)\n",
    "    open3d_geometry.compute_vertex_normals()\n",
    "\n",
    "    # Extract points, normals and adjacency information\n",
    "    points = open3d_geometry.vertices\n",
    "    adjacency_matrix = triangle_mesh_to_adjacency_matrix(open3d_geometry)\n",
    "    # Create a DGL graph from the adjacency matrix\n",
    "    dgl_graph = dgl.from_scipy(adjacency_matrix)\n",
    "\n",
    "    # Add node features (e.g., point coordinates) to the DGL graph\n",
    "    points_np = np.array(open3d_geometry.vertices)\n",
    "    normals_np = np.array(open3d_geometry.vertex_normals)\n",
    "    intensities_np = np.array(intensity_mesh.vertex_colors)\n",
    "    features = np.concatenate((points_np, intensities_np, normals_np), axis=1)\n",
    "    \n",
    "    dgl_graph.ndata['feat'] = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    return dgl_graph\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def pretrain(model, dataloaders, optimizer, max_epoch, device, scheduler, num_classes, lr_f, weight_decay_f, max_epoch_f, linear_prob, logger=None):\n",
    "    logging.info(\"start training..\")\n",
    "    train_loader, val_loader, test_loader, eval_train_loader = dataloaders\n",
    "\n",
    "    epoch_iter = tqdm(range(max_epoch))\n",
    "\n",
    "    if isinstance(train_loader, list) and len(train_loader) ==1:\n",
    "        train_loader = [train_loader[0].to(device)]\n",
    "        eval_train_loader = train_loader\n",
    "    if isinstance(val_loader, list) and len(val_loader) == 1:\n",
    "        val_loader = [val_loader[0].to(device)]\n",
    "        test_loader = val_loader\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        model.train()\n",
    "        loss_list = []\n",
    "\n",
    "        for subgraph in train_loader:\n",
    "            subgraph = subgraph.to(device)\n",
    "            loss, loss_dict = model(subgraph, subgraph.ndata[\"feat\"])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss = np.mean(loss_list)\n",
    "        epoch_iter.set_description(f\"# Epoch {epoch} | train_loss: {train_loss:.4f}\")\n",
    "        if logger is not None:\n",
    "            loss_dict[\"lr\"] = get_current_lr(optimizer)\n",
    "            logger.note(loss_dict, step=epoch)\n",
    "\n",
    "        if epoch == (max_epoch//2):\n",
    "            # print(model)\n",
    "            evaluate(model, (eval_train_loader, val_loader, test_loader), num_classes, lr_f, weight_decay_f, max_epoch_f, device, linear_prob, mute=True)\n",
    "    return model\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def evaluate(model, loaders, num_classes, lr_f, weight_decay_f, max_epoch_f, device, linear_prob=True, mute=False):\n",
    "    model.eval()\n",
    "    if linear_prob:\n",
    "        if len(loaders[0]) > 1:\n",
    "            x_all = {\"train\": [], \"val\": [], \"test\": []}\n",
    "            y_all = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for key, loader in zip([\"train\", \"val\", \"test\"], loaders):\n",
    "                    for subgraph in loader:\n",
    "                        subgraph = subgraph.to(device)\n",
    "                        feat = subgraph.ndata[\"feat\"]\n",
    "                        x = model.embed(subgraph, feat)\n",
    "                        # print(f'latent space: {x}')\n",
    "                        # print(f'latent space shape: {x.shape}')\n",
    "                        x_all[key].append(x)\n",
    "                        y_all[key].append(subgraph.ndata[\"feat\"])  \n",
    "            in_dim = x_all[\"train\"][0].shape[1]\n",
    "            encoder = LogisticRegression(in_dim, num_classes)\n",
    "            num_finetune_params = [p.numel() for p in encoder.parameters() if  p.requires_grad]\n",
    "            if not mute:\n",
    "                print(f\"num parameters for finetuning: {sum(num_finetune_params)}\")\n",
    "                # torch.save(x.cpu(), \"feat.pt\")\n",
    "            \n",
    "            encoder.to(device)\n",
    "            optimizer_f = create_optimizer(\"adam\", encoder, lr_f, weight_decay_f)\n",
    "            final_acc, estp_acc = mutli_graph_linear_evaluation(encoder, x_all, y_all, optimizer_f, max_epoch_f, device, mute)\n",
    "            return final_acc, estp_acc\n",
    "        else:\n",
    "            x_all = {\"train\": None, \"val\": None, \"test\": None}\n",
    "            y_all = {\"train\": None, \"val\": None, \"test\": None}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for key, loader in zip([\"train\", \"val\", \"test\"], loaders):\n",
    "                    for subgraph in loader:\n",
    "                        subgraph = subgraph.to(device)\n",
    "                        feat = subgraph.ndata[\"feat\"]\n",
    "                        x = model.embed(subgraph, feat)\n",
    "                        mask = subgraph.ndata[f\"{key}_mask\"]\n",
    "                        x_all[key] = x[mask]\n",
    "                        y_all[key] = subgraph.ndata[\"label\"][mask]  \n",
    "            in_dim = x_all[\"train\"].shape[1]\n",
    "            \n",
    "            encoder = LogisticRegression(in_dim, num_classes)\n",
    "            encoder = encoder.to(device)\n",
    "            optimizer_f = create_optimizer(\"adam\", encoder, lr_f, weight_decay_f)\n",
    "\n",
    "            x = torch.cat(list(x_all.values()))\n",
    "            y = torch.cat(list(y_all.values()))\n",
    "            num_train, num_val, num_test = [x.shape[0] for x in x_all.values()]\n",
    "            num_nodes = num_train + num_val + num_test\n",
    "            train_mask = torch.arange(num_train, device=device)\n",
    "            val_mask = torch.arange(num_train, num_train + num_val, device=device)\n",
    "            test_mask = torch.arange(num_train + num_val, num_nodes, device=device)\n",
    "            \n",
    "            final_acc, estp_acc = linear_probing_for_inductive_node_classiifcation(encoder, x, y, (train_mask, val_mask, test_mask), optimizer_f, max_epoch_f, device, mute)\n",
    "            return final_acc, estp_acc\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "#############################################################################################################\n",
    "\n",
    "def mutli_graph_linear_evaluation(model, feat, labels, optimizer, max_epoch, device, mute=False):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_val_epoch = 0\n",
    "    best_val_test_acc = 0\n",
    "\n",
    "    if not mute:\n",
    "        epoch_iter = tqdm(range(max_epoch))\n",
    "    else:\n",
    "        epoch_iter = range(max_epoch)\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        model.train()\n",
    "        for x, y in zip(feat[\"train\"], labels[\"train\"]):\n",
    "            out = model(None, x)\n",
    "            loss = criterion(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3)\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_out = []\n",
    "            test_out = []\n",
    "            for x, y in zip(feat[\"val\"], labels[\"val\"]):\n",
    "                val_pred = model(None, x)\n",
    "                val_out.append(val_pred)\n",
    "            val_out = torch.cat(val_out, dim=0).cpu().numpy()\n",
    "            val_label = torch.cat(labels[\"val\"], dim=0).cpu().numpy()\n",
    "            # val_out = np.where(val_out >= 0.0, 1.0, 0.0)\n",
    "\n",
    "            for x, y in zip(feat[\"test\"], labels[\"test\"]):\n",
    "                test_pred = model(None, x)# \n",
    "                test_out.append(test_pred)\n",
    "            test_out = torch.cat(test_out, dim=0).cpu().numpy()\n",
    "            test_label = torch.cat(labels[\"test\"], dim=0).cpu().numpy()\n",
    "            # test_out = np.where(test_out >= 0.0, 1.0, 0.0)\n",
    "\n",
    "            # val_acc = f1_score(val_label, val_out, average=\"micro\")\n",
    "            # test_acc = f1_score(test_label, test_out, average=\"micro\")\n",
    "\n",
    "            # mse = mean_squared_error(val_label, val_out)\n",
    "            val_acc = mean_absolute_error(val_label, val_out)\n",
    "            test_acc = mean_absolute_error(val_label, val_out)\n",
    "            # r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        if val_acc >= best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_epoch = epoch\n",
    "            best_val_test_acc = test_acc\n",
    "\n",
    "        if not mute:\n",
    "            epoch_iter.set_description(f\"# Epoch: {epoch}, train_loss:{loss.item(): .4f}, val_acc:{val_acc}, test_acc:{test_acc: .4f}\")\n",
    "\n",
    "    if mute:\n",
    "        print(f\"# IGNORE: --- Best ValAcc: {best_val_acc:.4f} in epoch {best_val_epoch}, Early-stopping-TestAcc: {best_val_test_acc:.4f},  Final-TestAcc: {test_acc:.4f}--- \")\n",
    "    else:\n",
    "        print(f\"--- Best ValAcc: {best_val_acc:.4f} in epoch {best_val_epoch}, Early-stopping-TestAcc: {best_val_test_acc:.4f}, Final-TestAcc: {test_acc:.4f} --- \")\n",
    "\n",
    "    return test_acc, best_val_test_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(object):\n",
    "    seed= 42\n",
    "    device= 0\n",
    "    max_epoch=200\n",
    "    warmup_steps=-1\n",
    "\n",
    "    num_heads=1\n",
    "    num_out_heads= 1 \n",
    "    num_layers= 2\n",
    "    num_hidden= 256\n",
    "    residual= False\n",
    "    in_drop= 0.2\n",
    "    attn_drop= 0.1\n",
    "    norm= None\n",
    "    lr= 0.001\n",
    "    weight_decay= 5e-4\n",
    "    negative_slope= 0.2\n",
    "    activation= \"prelu\"\n",
    "    mask_rate= 0.3\n",
    "    drop_edge_rate= 0.0\n",
    "    replace_rate: float = 0.15\n",
    "\n",
    "    encoder= \"gat\"\n",
    "    decoder= \"gat\"\n",
    "    loss_fn= \"sce\"\n",
    "    alpha_l= 2 #pow coefficient for sce loss\n",
    "    optimizer = \"adam\"\n",
    "    \n",
    "    max_epoch_f= 30\n",
    "    lr_f= 0.001\n",
    "    weight_decay_f= 0.0\n",
    "    linear_prob= True\n",
    "    concat_hidden = True\n",
    "    num_features = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = args.seed\n",
    "max_epoch = args.max_epoch\n",
    "max_epoch_f = args.max_epoch_f\n",
    "num_hidden = args.num_hidden\n",
    "num_layers = args.num_layers\n",
    "encoder_type = args.encoder\n",
    "decoder_type = args.decoder\n",
    "replace_rate = args.replace_rate\n",
    "\n",
    "optim_type = args.optimizer \n",
    "loss_fn = args.loss_fn\n",
    "\n",
    "lr = args.lr\n",
    "weight_decay = args.weight_decay\n",
    "lr_f = args.lr_f\n",
    "weight_decay_f = args.weight_decay_f\n",
    "linear_prob = args.linear_prob\n",
    "concat_hidden = args.concat_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=1100, num_edges=7046,\n",
      "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=1079, num_edges=7071,\n",
       "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs = []\n",
    "mesh = o3d.io.read_triangle_mesh(\"../../../local_data/organ_decimations_ply/2000/1000180/liver_mesh.ply\")\n",
    "dgl_graph = open3d_to_dgl_graph(mesh)\n",
    "dgl_graph = dgl_graph.remove_self_loop()\n",
    "dgl_graph = dgl_graph.add_self_loop()\n",
    "print(dgl_graph)\n",
    "graphs.append(dgl_graph)\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(\"../../../local_data/organ_decimations_ply/2000/1000071/liver_mesh.ply\")\n",
    "dgl_graph = open3d_to_dgl_graph(mesh)\n",
    "dgl_graph = dgl_graph.remove_self_loop()\n",
    "dgl_graph = dgl_graph.add_self_loop()\n",
    "graphs.append(dgl_graph)\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(\"../../../local_data/organ_decimations_ply/2000/2901448/liver_mesh.ply\")\n",
    "dgl_graph = open3d_to_dgl_graph(mesh)\n",
    "dgl_graph = dgl_graph.remove_self_loop()\n",
    "dgl_graph = dgl_graph.add_self_loop()\n",
    "graphs.append(dgl_graph)\n",
    "dgl_graph\n",
    "\n",
    "# decoder_g = pre_use_g.clone()\n",
    "# array_zeros = np.zeros((np.asarray(pre_use_g.ndata[\"feat\"]).shape[0], np.asarray(pre_use_g.ndata[\"feat\"]).shape[1]))\n",
    "# decoder_g.ndata['feat'] = torch.tensor(array_zeros, dtype=torch.float32)\n",
    "# dgl_graph.ndata.pop('feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1073, 3], y=[2, 4534], num_nodes=1073, val_pos_edge_index=[2, 106], test_pos_edge_index=[2, 213], train_pos_edge_index=[2, 3622], train_neg_adj_mask=[1073, 1073], val_neg_edge_index=[2, 106], test_neg_edge_index=[2, 213])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../data/gae/liver/data', 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.num_features = data.x.shape[1]\n",
    "num_classes = data.x.shape[1]\n",
    "scheduler = None\n",
    "logger = None\n",
    "args.num_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(args)\n",
    "model.to(device)\n",
    "optimizer = create_optimizer(optim_type, model, lr, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "estp_acc_list = []\n",
    "scheduler = None\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 15:34:15,204 - INFO - start training..\n",
      "# Epoch 100 | train_loss: 0.0004:  50%|█████     | 101/200 [00:24<00:34,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- Best ValAcc: 0.5383 in epoch 2, Early-stopping-TestAcc: 0.5383,  Final-TestAcc: 0.4947--- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 199 | train_loss: 0.0005: 100%|██████████| 200/200 [00:49<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "model = pretrain(model, (graphs, graphs, graphs, graphs), optimizer, max_epoch, device, scheduler, num_classes, lr_f, weight_decay_f, max_epoch_f, linear_prob, logger)\n",
    "# model = pretrain(model, (train_dataloader, valid_dataloader, test_dataloader, eval_train_dataloader, data), optimizer, max_epoch, device, scheduler, num_classes, lr_f, weight_decay_f, max_epoch_f, linear_prob, logger)\n",
    "model = model.cpu()\n",
    "\n",
    "# model = model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../models/liver_mesh.ply_graphmae.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "# subgraph = \"\"\n",
    "# feat = \"\"\n",
    "\n",
    "# x = model.embed(subgraph, feat)\n",
    "# model = model.to(device)\n",
    "\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "\n",
    "def triangle_mesh_to_adjacency_matrix(mesh):\n",
    "    # Get the vertices and triangles of the mesh\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    triangles = np.asarray(mesh.triangles)\n",
    "\n",
    "    # Create an empty adjacency matrix\n",
    "    n_vertices = len(vertices)\n",
    "    adjacency_matrix = sp.lil_matrix((n_vertices, n_vertices), dtype=np.float32)\n",
    "\n",
    "    # Iterate through the triangles and add edges to the adjacency matrix\n",
    "    for tri in triangles:\n",
    "        adjacency_matrix[tri[0], tri[1]] = 1.0\n",
    "        adjacency_matrix[tri[1], tri[0]] = 1.0\n",
    "        adjacency_matrix[tri[1], tri[2]] = 1.0\n",
    "        adjacency_matrix[tri[2], tri[1]] = 1.0\n",
    "        adjacency_matrix[tri[2], tri[0]] = 1.0\n",
    "        adjacency_matrix[tri[0], tri[2]] = 1.0\n",
    "\n",
    "    # Convert the adjacency matrix to a more efficient sparse matrix representation\n",
    "    adjacency_matrix = adjacency_matrix.tocsr()\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def open3d_to_dgl_graph(path, open3d_geometry):\n",
    "    intensity_path = path.replace(\"registered_meshes\",\"organ_decimations_ply\")\n",
    "    intensity_mesh = o3d.io.read_triangle_mesh(intensity_path)\n",
    "    open3d_geometry.compute_vertex_normals()\n",
    "\n",
    "    # Extract points, normals and adjacency information\n",
    "    points = open3d_geometry.vertices\n",
    "    adjacency_matrix = triangle_mesh_to_adjacency_matrix(open3d_geometry)\n",
    "    # Create a DGL graph from the adjacency matrix\n",
    "    dgl_graph = dgl.from_scipy(adjacency_matrix)\n",
    "\n",
    "    # Add node features (e.g., point coordinates) to the DGL graph\n",
    "    points_np = np.array(open3d_geometry.vertices)\n",
    "    normals_np = np.array(open3d_geometry.vertex_normals)\n",
    "    intensities_np = np.array(intensity_mesh.vertex_colors)\n",
    "    # features = np.concatenate((points_np, normals_np, intensities_np), axis=1)\n",
    "    features = points_np\n",
    "    \n",
    "    dgl_graph.ndata['feat'] = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    return dgl_graph\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "def get_single_subject(path, organ, subject):\n",
    "\n",
    "    mesh = o3d.io.read_triangle_mesh(f'{path}{subject}/{organ}')\n",
    "    dgl_graph = open3d_to_dgl_graph(f'{path}{subject}/{organ}', mesh)\n",
    "    dgl_graph = dgl_graph.remove_self_loop()\n",
    "    dgl_graph = dgl_graph.add_self_loop()\n",
    "\n",
    "    return dgl_graph\n",
    "\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import torch\n",
    "dgl_graph = get_single_subject(\"../../../../../../vol/aimspace/users/wyo/registered_meshes/2000/\", \"liver_mesh.ply\", \"1000071\")\n",
    "dgl_graph = dgl_graph\n",
    "model_path = \"../../models/liver_mesh.ply_graphmae_no_feat.pt\"\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "z = model.embed(dgl_graph, dgl_graph.ndata['feat'], True)\n",
    "\n",
    "rep, pred = model.decode(dgl_graph, z)\n",
    "pred = pred.detach().cpu().numpy()\n",
    "rep = rep.detach().cpu().numpy()\n",
    "\n",
    "z = z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_embedding = np.mean(rep, axis=0)\n",
    "graph_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-09-26 14:24:28,075 - utils - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO - 2023-09-26 14:24:28,076 - utils - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import torch\n",
    "dgl_graph = get_single_subject(\"../../../../../../vol/aimspace/users/wyo/registered_meshes/2000/\", \"liver_mesh.ply\", \"1000071\")\n",
    "dgl_graph = dgl_graph\n",
    "model_path = \"../../models/liver_mesh.ply_graphmae_gat_pool_mlp.pt\"\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "z = model.embed(dgl_graph, dgl_graph.ndata['feat'], False)\n",
    "\n",
    "z = z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "with open(f'../../../../../../vol/aimspace/users/wyo/latent_spaces/vertices_prediction_sort_pool_gmae/liver/1000071', \"rb\") as fp:\n",
    "    x = pkl.load(fp)\n",
    "fp.close()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.nn import SortPooling\n",
    "sortpool = SortPooling(k=1000)\n",
    "x= sortpool(dgl_graph, dgl_graph.ndata['feat']) \n",
    "x.shape[1]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=1087, num_edges=7067,\n",
       "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
